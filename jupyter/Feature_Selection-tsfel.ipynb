{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mUnable to start Kernel 'venv (Python 3.8.1)' due to connection timeout. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "## General imports\n",
    "import sys, os, joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "## sklearn imports\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, VarianceThreshold, SelectFromModel\n",
    "from sklearn.model_selection import GroupKFold, cross_validate\n",
    "\n",
    "\n",
    "# Define local directories\n",
    "dir_current = os.getcwd()\n",
    "dir_base = os.path.dirname(dir_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names, dtype=None):\n",
    "        self.attribute_names = attribute_names\n",
    "        self.dtype = dtype\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X_selected = X[self.attribute_names]\n",
    "        if self.dtype:\n",
    "            return X_selected.astype(self.dtype).values\n",
    "        return X_selected.values\n",
    "\n",
    "class CorrelationThreshold(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    \"\"\"Feature selector that removes all correlated features.\n",
    "\n",
    "    This feature selection algorithm looks only at the features (X), not the\n",
    "    desired outputs (y), and can thus be used for unsupervised learning.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    threshold : float, default=0.95\n",
    "        Features with a training-set correlation higher than this threshold will\n",
    "        be removed. The default is to keep all features with non-zero variance,\n",
    "        i.e. remove the features that have the same value in all samples.\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    selected_features_ : list, shape (n_features)\n",
    "        Returns a list with the selected feature names.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, threshold = 0.95):\n",
    "        self.threshold = threshold\n",
    "        self.to_drop = None\n",
    "        self.to_keep = None\n",
    "\n",
    "    def fit (self, X, y = None ): \n",
    "        '''\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
    "            Sample vectors from which to compute variances.\n",
    "        y : any, default=None\n",
    "            Ignored. This parameter exists only for compatibility with\n",
    "            sklearn.pipeline.Pipeline.\n",
    "        Returns\n",
    "        -------\n",
    "        self\n",
    "        '''\n",
    "        X = pd.DataFrame(X)\n",
    "        corr_matrix = X.corr().abs()\n",
    "        upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "        self.to_drop = [column for column in upper.columns if any(upper[column] > self.threshold)]\n",
    "        self.to_keep = list(set(X.columns) - set(self.to_drop))\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X, y = None):\n",
    "        X_selected = X[self.to_keep]\n",
    "        return X_selected\n",
    "    \n",
    "    def get_support(self):\n",
    "        return self.to_keep\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset name: df-all-dev\n",
      "Dataset shape: (26338, 3335)\n"
     ]
    }
   ],
   "source": [
    "# select dataframe\n",
    "df_name = 'df-all-dev'\n",
    "print('Dataset name:', df_name)\n",
    "# directory where the datasets are located\n",
    "df_path = os.path.join(dir_base, 'data', 'tsfel', \"{}.csv\".format(df_name))\n",
    "# imports all datasets in directory\n",
    "df = pd.read_csv( df_path, \n",
    "        index_col = ['Timestamp'], \n",
    "        parse_dates = ['Timestamp'],\n",
    "        dayfirst = True,\n",
    "        date_parser = lambda x: pd.to_datetime(x, format = '%Y-%m-%d %H:%M:%S.%f'))\n",
    "print(\"Dataset shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert a random variable for feature importance comparison\n",
    "df.insert(0,                # position\n",
    "            'random',       # column name\n",
    "            np.random.RandomState(1234).uniform(low=0, high=1, size = (df.shape[0]),)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric Features: Index(['random', 'Back.Acc.X_Absolute energy',\n",
      "       'Back.Acc.X_Area under the curve', 'Back.Acc.X_Autocorrelation',\n",
      "       'Back.Acc.X_Centroid', 'Back.Acc.X_ECDF Percentile Count_0',\n",
      "       'Back.Acc.X_ECDF Percentile Count_1', 'Back.Acc.X_ECDF Percentile_0',\n",
      "       'Back.Acc.X_ECDF Percentile_1', 'Back.Acc.X_ECDF_0',\n",
      "       ...\n",
      "       'Neck.Gyr.Z_Wavelet variance_0', 'Neck.Gyr.Z_Wavelet variance_1',\n",
      "       'Neck.Gyr.Z_Wavelet variance_2', 'Neck.Gyr.Z_Wavelet variance_3',\n",
      "       'Neck.Gyr.Z_Wavelet variance_4', 'Neck.Gyr.Z_Wavelet variance_5',\n",
      "       'Neck.Gyr.Z_Wavelet variance_6', 'Neck.Gyr.Z_Wavelet variance_7',\n",
      "       'Neck.Gyr.Z_Wavelet variance_8', 'Neck.Gyr.Z_Zero crossing rate'],\n",
      "      dtype='object', length=3331)\n",
      "Number of numeric features: 3331\n",
      "Categorical features: ['Breed']\n"
     ]
    }
   ],
   "source": [
    "# # Feature preprocessing \n",
    "# # numeric\n",
    "# numeric_features = df.columns[:-5]\n",
    "# print(\"Numeric Features:\",  numeric_features)\n",
    "# print(\"Number of numeric features:\", len(numeric_features))\n",
    "# numeric_transformer = Pipeline([\n",
    "#         ('ft', DataFrameSelector(numeric_features,'float64')),\n",
    "#         ('var', VarianceThreshold()),\n",
    "#         ('cor', CorrelationThreshold())\n",
    "#      ])\n",
    "\n",
    "# # categorical\n",
    "# categorical_features = [\"Breed\"]\n",
    "# print(\"Categorical features:\", categorical_features)\n",
    "# categorical_transformer = Pipeline([\n",
    "#         ('ft', DataFrameSelector(categorical_features,'category')),\n",
    "#         ('enc', OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "#     ])\n",
    "\n",
    "# # Preprocessor\n",
    "# preprocessor = ColumnTransformer([\n",
    "#         (\"num\", numeric_transformer, numeric_features),\n",
    "#         (\"cat\", categorical_transformer, categorical_features),\n",
    "#     ])\n",
    "\n",
    "# # Random forest pipeline for feature selection\n",
    "# rf_pipe = Pipeline([\n",
    "#         ('prep', preprocessor),\n",
    "#         ('clf', RandomForestClassifier(random_state= 42))\n",
    "#     ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = df.columns[:-5]\n",
    "pipe = Pipeline([\n",
    "        ('ft', DataFrameSelector(feat,'float64')),\n",
    "        ('var', VarianceThreshold()),\n",
    "        #('cor', CorrelationThreshold()),\n",
    "        ('clf', RandomForestClassifier(random_state= 42))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--- 622.0925557613373 seconds ---\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupKFold, GridSearchCV\n",
    "\n",
    "start_time = time()\n",
    "# using df_train to check on the Feature Importances for the RF classifier\n",
    "# this will help me pick an optimal  number for the feature selection algorithm\n",
    "# rf_cv = cross_validate(\n",
    "#             estimator = rf_pipe, \n",
    "#             X = df.loc[:, feat].values, \n",
    "#             y = df.loc[:, 'Position'].values, \n",
    "#             groups = df.loc[:,'Dog'],\n",
    "#             cv= GroupKFold(n_splits = 3), \n",
    "#             scoring = 'f1_weighted', \n",
    "#             return_train_score= True,\n",
    "#             return_estimator = True,\n",
    "#             n_jobs = -1\n",
    "#         )\n",
    "\n",
    "# prepare dataframe for evaluation: select features, label,\n",
    "#   cv strategy (group = dogs, stractified folds labels proportion)\n",
    "X = df.loc[:, feat]\n",
    "y = df.loc[:, 'Position'].values\n",
    "\n",
    "groups = df.loc[:,'Dog']\n",
    "params = dict()\n",
    "cv = GroupKFold(n_splits = 10).split(X, y, groups = groups)\n",
    "gs = GridSearchCV(pipe, param_grid = params, \n",
    "        scoring = 'f1_weighted', \\\n",
    "        n_jobs = 40, cv = cv, return_train_score = True)\n",
    "gs.fit(X,y, groups = groups)\n",
    "\n",
    "end_time = time()\n",
    "duration = end_time - start_time\n",
    "print(\"\\n\\n--- %s seconds ---\\n\\n\" % (duration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=<generator object _BaseKFold.split at 0x2b4ebda49d50>,\n",
      "             estimator=Pipeline(steps=[('ft',\n",
      "                                        DataFrameSelector(attribute_names=Index(['random', 'Back.Acc.X_Absolute energy',\n",
      "       'Back.Acc.X_Area under the curve', 'Back.Acc.X_Autocorrelation',\n",
      "       'Back.Acc.X_Centroid', 'Back.Acc.X_ECDF Percentile Count_0',\n",
      "       'Back.Acc.X_ECDF Percentile Count_1', 'Back.Acc.X_ECDF Percen...\n",
      "       'Neck.Gyr.Z_Wavelet variance_4', 'Neck.Gyr.Z_Wavelet variance_5',\n",
      "       'Neck.Gyr.Z_Wavelet variance_6', 'Neck.Gyr.Z_Wavelet variance_7',\n",
      "       'Neck.Gyr.Z_Wavelet variance_8', 'Neck.Gyr.Z_Zero crossing rate'],\n",
      "      dtype='object', length=3331),\n",
      "                                                          dtype='float64')),\n",
      "                                       ('var', VarianceThreshold()),\n",
      "                                       ('clf',\n",
      "                                        RandomForestClassifier(random_state=42))]),\n",
      "             n_jobs=40, param_grid={}, return_train_score=True,\n",
      "             scoring='f1_weighted')\n",
      "/ichec/home/users/mmarcato/dog_posture/jupyter/TSFEL-SELECT.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/ichec/home/users/mmarcato/dog_posture/jupyter/TSFEL-SELECT.pkl']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class gs_results:\n",
    "    # Storing Grid Search results\n",
    "    def __init__(self, gs):\n",
    "        self.cv_results_ = gs.cv_results_\n",
    "        self.best_estimator_ = gs.best_estimator_\n",
    "        self.best_params_ = gs.best_params_\n",
    "        self.best_score_ = gs.best_score_\n",
    "        \n",
    "print(gs)\n",
    "run = \"TSFEL-SELECT.pkl\"\n",
    "# save gs results to pickle file\n",
    "gs_path = os.path.join(dir_current, run)\n",
    "print(gs_path)\n",
    "joblib.dump(gs_results(gs), gs_path, compress = 1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_rf = pd.DataFrame({\n",
    "        'features': feat[np.where(gs.best_estimator_['var'].variances_ != 0)], \n",
    "        'importance':  gs.best_estimator_['clf'].feature_importances_\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/ichec/home/users/mmarcato/dog_posture/jupyter/TSFEL-FS.pkl']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(importance_rf, os.path.join(dir_current, 'TSFEL-FS.pkl'), compress = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance_threshold = importance_rf.loc[importance_rf['features'] == 'random','importance'].values[0]\n",
    "type(importance_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_rf.sort_values('importance', ascending = False, ignore_index = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_rf['keep'] = importance_rf['importance'] > importance_threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features in original dataset:  3331 \n",
      "Number of features (Variance):  3150 \n",
      "Number of features (Random threshold): 2344\n"
     ]
    }
   ],
   "source": [
    "print('Number of features in original dataset: ', len(feat),\n",
    "      '\\nNumber of features (Variance): ', importance_rf.shape[0], \n",
    "      '\\nNumber of features (Random threshold):', importance_rf['keep'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/ichec/home/users/mmarcato/dog_posture/jupyter/TSFEL-FEATURES.pkl']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(importance_rf.loc[importance_rf['keep'], 'features'], os.path.join(dir_current, 'TSFEL-FEATURES.pkl'), compress = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = joblib.load(os.path.join(dir_current, 'TSFEL-FEATURES.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7000,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class cv_results:\n",
    "#     # Storing Cross Validate results and the feature names\n",
    "#     def __init__(self, cv, feat):\n",
    "#         self.test_score = cv.test_score\n",
    "#         self.train_score = cv.train_score\n",
    "#         self.fit_time = cv.fit_time\n",
    "#         self.score_time = cv.score_time\n",
    "#         self.estimator = cv.estimator\n",
    "#         self.feat = feat\n",
    "\n",
    "# print(rf_cv)\n",
    "# run = \"TSFEL-SELECT.pkl\"\n",
    "# # save gs results to pickle file\n",
    "# gs_path = os.path.join(dir_current, run)\n",
    "# print(gs_path)\n",
    "# joblib.dump(cv_results(rf_cv, feat), gs_path, compress = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7e46ae5f06cc793114e88341499be929494725c4f8677908e43c2abd4e588c46"
  },
  "kernelspec": {
   "display_name": "Python [conda env:venv]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
